{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SeaOfFrost/BookCoverClassifier/blob/master/ResNet_Cover_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkEqxbl8iZTE"
   },
   "source": [
    "# Load Required Folder and check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "raJdcWAF1Iog",
    "outputId": "3476b32a-beed-4724-8875-46a2042e1c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ������ C �еľ�û�б�ǩ��\n",
      " �������к��� 8C05-667A\n",
      "\n",
      " c:\\Users\\a6377\\Desktop\\Library Inventory Management System SMU\\classification ��Ŀ¼\n",
      "\n",
      "2024/11/06  21:54    <DIR>          .\n",
      "2024/11/06  21:44    <DIR>          ..\n",
      "2024/11/06  20:55    <DIR>          CNN\n",
      "2024/11/04  22:48    <DIR>          data\n",
      "2024/11/04  23:10               813 main.py\n",
      "2024/11/06  21:54            19,505 ResNet_Cover_Classifier.ipynb\n",
      "2024/11/04  22:34       102,967,424 resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "               3 ���ļ�    102,987,742 �ֽ�\n",
      "               4 ��Ŀ¼ 430,339,002,368 �����ֽ�\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Hd8hM1vu1Ofg",
    "outputId": "be5bb329-8ef9-44c9-b351-adc36b6cc423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] 系统找不到指定的路径。: 'drive/My Drive/Book Classifier/book-dataset/Task1/'\n",
      "c:\\Users\\a6377\\Desktop\\Library Inventory Management System SMU\\classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a6377\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/Book Classifier/book-dataset/Task1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "iQtnzx5xCuJk",
    "outputId": "59726c55-a63a-46f5-ba9b-3df39fa6d274"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TW-LTmetifIg"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wtGCLTDCHbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x252470f5c70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uq4D4u2biiEA"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6cOvbjhCIgM"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './images\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m      1\u001b[0m data_transforms \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      3\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     ])\n\u001b[0;32m     19\u001b[0m }\n\u001b[0;32m     21\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 22\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m     25\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     26\u001b[0m                                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     27\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m     28\u001b[0m dataset_sizes \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28mlen\u001b[39m(image_datasets[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: './images\\\\train'"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = './images'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=8)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFcvCTj_ikHQ"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "binfooGnCKbo"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nW7opK5CNrc"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.2),\n",
    "                         nn.Linear(512, 10),\n",
    "                         nn.LogSoftmax(dim=1))\n",
    "model = model.to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EB1UajAliqzY"
   },
   "source": [
    "Train model and save weights after completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eT-uhFj8CPoc",
    "outputId": "07725d76-4db7-48d9-f1dc-adce65abc41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 1.7561 Acc: 0.3805\n",
      "val Loss: 1.6226 Acc: 0.4417\n",
      "\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 1.7384 Acc: 0.3860\n",
      "val Loss: 1.6124 Acc: 0.4393\n",
      "\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 1.7187 Acc: 0.4016\n",
      "val Loss: 1.6007 Acc: 0.4446\n",
      "\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 1.7047 Acc: 0.4032\n",
      "val Loss: 1.5810 Acc: 0.4405\n",
      "\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 1.6838 Acc: 0.4151\n",
      "val Loss: 1.5724 Acc: 0.4498\n",
      "\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 1.6935 Acc: 0.4114\n",
      "val Loss: 1.5883 Acc: 0.4457\n",
      "\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 1.6757 Acc: 0.4179\n",
      "val Loss: 1.5650 Acc: 0.4527\n",
      "\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 1.6599 Acc: 0.4233\n",
      "val Loss: 1.5588 Acc: 0.4673\n",
      "\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 1.6613 Acc: 0.4227\n",
      "val Loss: 1.5589 Acc: 0.4562\n",
      "\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 1.6608 Acc: 0.4144\n",
      "val Loss: 1.5673 Acc: 0.4492\n",
      "\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 1.6425 Acc: 0.4218\n",
      "val Loss: 1.5467 Acc: 0.4446\n",
      "\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 1.6528 Acc: 0.4269\n",
      "val Loss: 1.5587 Acc: 0.4516\n",
      "\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 1.6349 Acc: 0.4314\n",
      "val Loss: 1.5874 Acc: 0.4545\n",
      "\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 1.6345 Acc: 0.4284\n",
      "val Loss: 1.5765 Acc: 0.4376\n",
      "\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 1.6362 Acc: 0.4292\n",
      "val Loss: 1.5401 Acc: 0.4621\n",
      "\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 1.6389 Acc: 0.4284\n",
      "val Loss: 1.5844 Acc: 0.4504\n",
      "\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 1.6132 Acc: 0.4386\n",
      "val Loss: 1.5432 Acc: 0.4656\n",
      "\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 1.6239 Acc: 0.4308\n",
      "val Loss: 1.5802 Acc: 0.4527\n",
      "\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 1.6187 Acc: 0.4342\n",
      "val Loss: 1.5798 Acc: 0.4574\n",
      "\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 1.6195 Acc: 0.4373\n",
      "val Loss: 1.5309 Acc: 0.4597\n",
      "\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 1.6021 Acc: 0.4422\n",
      "val Loss: 1.5732 Acc: 0.4533\n",
      "\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 1.6082 Acc: 0.4375\n",
      "val Loss: 1.5675 Acc: 0.4510\n",
      "\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 1.6132 Acc: 0.4355\n",
      "val Loss: 1.5401 Acc: 0.4592\n",
      "\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 1.5854 Acc: 0.4514\n",
      "val Loss: 1.5356 Acc: 0.4592\n",
      "\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 1.5988 Acc: 0.4440\n",
      "val Loss: 1.5311 Acc: 0.4615\n",
      "\n",
      "Training complete in 28m 0s\n",
      "Best val Acc: 0.467328\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, num_epochs=25)\n",
    "torch.save(model_ft.state_dict(), 'Weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfrnkQk7ixUk"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-Sv_aZCSRRE"
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion):\n",
    "    \n",
    "    path = 'Weights.pt'\n",
    "    since = time.time()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        total_labels.append(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.shape)\n",
    "            total_preds.append(outputs.detach().cpu())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    loss = running_loss / dataset_sizes['test']\n",
    "    acc = running_corrects.double() / dataset_sizes['test']\n",
    "\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(loss, acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "3VrXb-lkU5oE",
    "outputId": "714e6883-3a89-4d1e-c3ba-805eec173b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6499 Acc: 0.4142\n",
      "Training complete in 2m 7s\n"
     ]
    }
   ],
   "source": [
    "preds, labels = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMHbd8kCZ9YY"
   },
   "outputs": [],
   "source": [
    "from torch import topk\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "E8F3AkcsaWEE",
    "outputId": "b7fe78f5-af1c-4cb4-87c2-9e59be6d198a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Accuracy is: 41.42361068725586\n",
      "Top 3 Accuracy is: 71.61458587646484\n",
      "Top 5 Accuracy is: 87.1875\n"
     ]
    }
   ],
   "source": [
    "total_top1 = 0\n",
    "total_top3 = 0\n",
    "total_top5 = 0\n",
    "for i in range(len(preds)):\n",
    "  top1, top3, top5 = accuracy(preds[i], labels[i], topk = (1, 3, 5))\n",
    "  total_top1 += top1\n",
    "  total_top3 += top3\n",
    "  total_top5 += top5\n",
    "print(f\"Top 1 Accuracy is: {total_top1/len(preds)}\")\n",
    "print(f\"Top 3 Accuracy is: {total_top3/len(preds)}\")\n",
    "print(f\"Top 5 Accuracy is: {total_top5/len(preds)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyME6UoD/NZc/rqh25kKXh+V",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1GR02cWca7f_3AeVlXfwQ3E3vjbp9hShn",
   "name": "ResNet Cover Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
